{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4837752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='kalshi-456121'\n",
    "BUCKET_NAME='kalshi-data-lake'\n",
    "CLUSTER='kalshi-dataproc-cluster'\n",
    "REGION='us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1ffa5",
   "metadata": {},
   "source": [
    "## Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b617b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:==================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows:  7893212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "PROJECT_ID='kalshi-456121'\n",
    "BUCKET_NAME='kalshi-data-lake'\n",
    "CLUSTER='kalshi-dataproc-cluster'\n",
    "REGION='us-central1'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# GCS bucket path to the Parquet file or folder\n",
    "# gcs_path = f\"gs://{BUCKET_NAME}/trades/historical/01_2025/trades_2025-04-16T19.parquet\"\n",
    "gcs_path = f\"gs://{BUCKET_NAME}/trades/*.parquet\"\n",
    "\n",
    "# Path to the GCS connector jar\n",
    "from os.path import expanduser\n",
    "gcs_connector_path = \"gcs-connector-hadoop3-latest.jar\"\n",
    "# Start a local Spark session with the GCS connector\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"QueryGCSParquet\") \\\n",
    "    .config(\"spark.jars\", gcs_connector_path) \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"creds/gcp-sa-key.json\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", \"kalshi-456121\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the Parquet file from GCS\n",
    "df = spark.read.parquet(gcs_path)\n",
    "print(\"Total rows: \", df.count())\n",
    "\n",
    "# Perform a simple query\n",
    "# df.select(\"ticker\", \"count\", \"yes_price\", \"created_time\").show(10)\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba8f6f",
   "metadata": {},
   "source": [
    "## Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a72e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ticker='KXETHD-25APR2515-T1279.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,280 or above', yes_sub_title='$1,280 or above', no_sub_title='$1,280 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1279.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1279.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1259.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,260 or above', yes_sub_title='$1,260 or above', no_sub_title='$1,260 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1259.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1259.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1239.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,240 or above', yes_sub_title='$1,240 or above', no_sub_title='$1,240 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1239.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1239.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1219.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,220 or above', yes_sub_title='$1,220 or above', no_sub_title='$1,220 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1219.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1219.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T999.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,000 or above', yes_sub_title='$1,000 or above', no_sub_title='$1,000 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 999.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=999.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T979.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$980 or above', yes_sub_title='$980 or above', no_sub_title='$980 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 979.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=979.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1199.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,200 or above', yes_sub_title='$1,200 or above', no_sub_title='$1,200 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1199.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1199.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1179.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,180 or above', yes_sub_title='$1,180 or above', no_sub_title='$1,180 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1179.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1179.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1159.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,160 or above', yes_sub_title='$1,160 or above', no_sub_title='$1,160 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1159.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1159.99, cap_strike=None)\n",
      "Row(ticker='KXETHD-25APR2515-T1139.99', event_ticker='KXETHD-25APR2515', market_type='binary', title='Ethereum price at Apr 25, 2025 at 3pm EDT?', subtitle='$1,140 or above', yes_sub_title='$1,140 or above', no_sub_title='$1,140 or above', open_time='2025-04-25T18:00:00Z', close_time='2025-04-25T19:00:00Z', expected_expiration_time='2025-04-25T19:05:00Z', expiration_time='2025-05-02T19:00:00Z', latest_expiration_time='2025-05-02T19:00:00Z', settlement_timer_seconds=60, status='initialized', response_price_units='usd_cent', notional_value=100, tick_size=1, yes_bid=0, yes_ask=0, no_bid=100, no_ask=100, last_price=0, previous_yes_bid=0, previous_yes_ask=0, previous_price=0, volume=0, volume_24h=0, liquidity=0, open_interest=0, result='', can_close_early=True, expiration_value='', category='', risk_limit_cents=0, strike_type='greater', custom_strike=None, rules_primary=\"If the simple average of the sixty seconds of CF Benchmarks' Ethereum Real-Time Index (ERTI) before 3 PM EDT is above 1139.99 at 3 PM EDT on Apr 25, 2025, then the market resolves to Yes.\", rules_secondary=\"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\", day_str='2025-04-25', floor_strike=1139.99, cap_strike=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# GCS bucket path to the Parquet file or folder\n",
    "gcs_path = f\"gs://{BUCKET_NAME}/markets/01012025_to_04242025v2.parquet\"\n",
    "\n",
    "# Path to the GCS connector jar\n",
    "from os.path import expanduser\n",
    "gcs_connector_path = expanduser(\"~/Documents/gcloud/gcs-connector-hadoop3-latest.jar\")\n",
    "# Start a local Spark session with the GCS connector\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"QueryGCSParquet\") \\\n",
    "    .config(\"spark.jars\", gcs_connector_path) \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"/Users/jakewatson/hello/kalshi/creds/gcp-sa-key.json\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", \"kalshi-456121\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the Parquet file from GCS\n",
    "df = spark.read.parquet(gcs_path)\n",
    "\n",
    "# Perform a simple query\n",
    "last_10 = df.collect()[-10:]\n",
    "for row in last_10[:1]:\n",
    "    print(row)\n",
    "# df.show(10)\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e4ed5",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1321bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/24 11:55:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+--------------------+----------------------+------------------+--------------------+-----------+-------------+\n",
      "|        event_ticker|    series_ticker|           sub_title|               title|collateral_return_type|mutually_exclusive|            category|strike_date|strike_period|\n",
      "+--------------------+-----------------+--------------------+--------------------+----------------------+------------------+--------------------+-----------+-------------+\n",
      "|      KXROBOTMARS-35|      KXROBOTMARS|         Before 2035|Will a humanoid r...|                      |             false|Science and Techn...|       NULL|         NULL|\n",
      "|       KXNEXTPOPE-35|       KXNEXTPOPE|         Before 2035|Who will the next...|                MECNET|              true|               World|       NULL|         NULL|\n",
      "|    KXLALEADEROUT-35|    KXLALEADEROUT|         Before 2035|Which of these La...|                MECNET|              true|            Politics|       NULL|         NULL|\n",
      "|    KXG7LEADEROUT-35|    KXG7LEADEROUT|         Before 2035|Which of these G7...|                MECNET|              true|            Politics|       NULL|         NULL|\n",
      "|    KXEULEADEROUT-35|    KXEULEADEROUT|         Before 2035|Which of these Eu...|                MECNET|              true|            Politics|       NULL|         NULL|\n",
      "|       KXBRUVSEAT-35|       KXBRUVSEAT|In the next U.K. ...|Will Andrew Tate'...|                      |             false|           Elections|       NULL|         NULL|\n",
      "|  KXASIALEADEROUT-35|  KXASIALEADEROUT|         Before 2035|Which of these As...|                MECNET|              true|            Politics|       NULL|         NULL|\n",
      "|KXAFRICALEADEROUT-35|KXAFRICALEADEROUT|         Before 2035|Which of these Af...|                MECNET|              true|            Politics|       NULL|         NULL|\n",
      "|     JOBLESS-21AUG28|        KXJOBLESS|From Aug 22-28, 2021|Initial jobless c...|                      |             false|           Economics|       NULL|         NULL|\n",
      "|           EUCLIMATE|      KXEUCLIMATE|             By 2030|EU meets its 2030...|                      |             false| Climate and Weather|       NULL|         NULL|\n",
      "+--------------------+-----------------+--------------------+--------------------+----------------------+------------------+--------------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# GCS bucket path to the Parquet file or folder\n",
    "gcs_path = f\"gs://{BUCKET_NAME}/events/all.parquet\"\n",
    "\n",
    "# Path to the GCS connector jar\n",
    "from os.path import expanduser\n",
    "gcs_connector_path = expanduser(\"~/Documents/gcloud/gcs-connector-hadoop3-latest.jar\")\n",
    "# Start a local Spark session with the GCS connector\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"QueryGCSParquet\") \\\n",
    "    .config(\"spark.jars\", gcs_connector_path) \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"/Users/jakewatson/hello/kalshi/creds/gcp-sa-key.json\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", \"kalshi-456121\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the Parquet file from GCS\n",
    "df = spark.read.parquet(gcs_path)\n",
    "\n",
    "# Perform a simple query\n",
    "df.show(10)\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'can_close_early': True,\n",
      " 'category': '',\n",
      " 'close_time': '2026-12-31T15:00:00Z',\n",
      " 'custom_strike': {'Candidate': 'Mike Lawler'},\n",
      " 'event_ticker': 'KXGOVNYNOMR-26',\n",
      " 'expected_expiration_time': '2026-12-31T15:00:00Z',\n",
      " 'expiration_time': '2026-12-31T15:00:00Z',\n",
      " 'expiration_value': '',\n",
      " 'last_price': 0,\n",
      " 'latest_expiration_time': '2026-12-31T15:00:00Z',\n",
      " 'liquidity': 0,\n",
      " 'market_type': 'binary',\n",
      " 'no_ask': 100,\n",
      " 'no_bid': 100,\n",
      " 'no_sub_title': 'Mike Lawler',\n",
      " 'notional_value': 100,\n",
      " 'open_interest': 0,\n",
      " 'open_time': '2025-04-17T14:00:00Z',\n",
      " 'previous_price': 0,\n",
      " 'previous_yes_ask': 0,\n",
      " 'previous_yes_bid': 0,\n",
      " 'response_price_units': 'usd_cent',\n",
      " 'result': '',\n",
      " 'risk_limit_cents': 0,\n",
      " 'rules_primary': 'If Mike Lawler wins the nomination for the Republican Party '\n",
      "                  'to contest the 2026 New York Governorship, then the market '\n",
      "                  'resolves to Yes.',\n",
      " 'rules_secondary': '',\n",
      " 'settlement_timer_seconds': 300,\n",
      " 'status': 'initialized',\n",
      " 'strike_type': 'custom',\n",
      " 'subtitle': '',\n",
      " 'tick_size': 1,\n",
      " 'ticker': 'KXGOVNYNOMR-26-MLAW',\n",
      " 'title': 'Wil Mike Lawler be the Republican nominee for Governor in New York?',\n",
      " 'volume': 0,\n",
      " 'volume_24h': 0,\n",
      " 'yes_ask': 0,\n",
      " 'yes_bid': 0,\n",
      " 'yes_sub_title': 'Mike Lawler'}\n",
      "dict_keys(['ticker', 'event_ticker', 'market_type', 'title', 'subtitle', 'yes_sub_title', 'no_sub_title', 'open_time', 'close_time', 'expected_expiration_time', 'expiration_time', 'latest_expiration_time', 'settlement_timer_seconds', 'status', 'response_price_units', 'notional_value', 'tick_size', 'yes_bid', 'yes_ask', 'no_bid', 'no_ask', 'last_price', 'previous_yes_bid', 'previous_yes_ask', 'previous_price', 'volume', 'volume_24h', 'liquidity', 'open_interest', 'result', 'can_close_early', 'expiration_value', 'category', 'risk_limit_cents', 'strike_type', 'custom_strike', 'rules_primary', 'rules_secondary'])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pprint\n",
    "\n",
    "def fetch_markets():\n",
    "    url = \"https://api.elections.kalshi.com/trade-api/v2/markets\"\n",
    "    r = requests.get(url)\n",
    "    markets = r.json().get(\"markets\", [])\n",
    "    print(markets[0])\n",
    "    print(markets[0]['status'])\n",
    "    print(\"Keys: \", markets[0].keys())\n",
    "\n",
    "fetch_markets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8ebb3",
   "metadata": {},
   "source": [
    "## Clean and push to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e865678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/26 18:27:33 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+---------+--------+----------+----------+------------+\n",
      "|            trade_id|              ticker|count|        created_time|yes_price|no_price|taker_side|bid_amount|created_date|\n",
      "+--------------------+--------------------+-----+--------------------+---------+--------+----------+----------+------------+\n",
      "|13e20041-a226-47f...|KXWMARMAD-25R64G1...|   73|2025-03-21T23:59:...|       99|       1|        no|      0.73|  2025-03-21|\n",
      "|40d20184-6d4f-4d3...|KXMARMAD-25R64G7-...|    5|2025-03-21T23:59:...|       49|      51|       yes|      2.45|  2025-03-21|\n",
      "|48e5bf41-187a-44f...|KXMARMAD-25R64G30-UK|   25|2025-03-21T23:59:...|       92|       8|        no|       2.0|  2025-03-21|\n",
      "|388abf18-291b-4dc...|KXMARMAD-25R64G7-UNM|  234|2025-03-21T23:59:...|       53|      47|       yes|    124.02|  2025-03-21|\n",
      "|980f8084-2678-419...|   KXELECTUKRAINE-26|  207|2025-03-21T23:59:...|       41|      59|        no|    122.13|  2025-03-21|\n",
      "|c74e7de2-7a21-410...|KXMARMAD-25R64G30...|  405|2025-03-21T23:59:...|        8|      92|       yes|      32.4|  2025-03-21|\n",
      "|0bdae6dc-47d8-4cb...|KXMARMAD-25R64G7-UNM|  200|2025-03-21T23:59:...|       53|      47|       yes|     106.0|  2025-03-21|\n",
      "|cb23b998-544e-4d5...|KXMARMAD-25R64G7-UNM|   80|2025-03-21T23:59:...|       53|      47|       yes|      42.4|  2025-03-21|\n",
      "|d366edce-e337-408...|KXWMARMAD-25R64G2...|   20|2025-03-21T23:59:...|       55|      45|        no|       9.0|  2025-03-21|\n",
      "|1cc0e993-7658-4a0...|KXMARMAD-25R32G11...|  100|2025-03-21T23:59:...|       53|      47|       yes|      53.0|  2025-03-21|\n",
      "+--------------------+--------------------+-----+--------------------+---------+--------+----------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- created_date: date (nullable = true)\n",
      " |-- yes_price_close: long (nullable = true)\n",
      " |-- yes_price_high: long (nullable = true)\n",
      " |-- yes_price_low: long (nullable = true)\n",
      " |-- no_price_close: long (nullable = true)\n",
      " |-- no_price_high: long (nullable = true)\n",
      " |-- no_price_low: long (nullable = true)\n",
      " |-- daily_total_bid_amount_yes: double (nullable = true)\n",
      " |-- daily_total_bid_amount_no: double (nullable = true)\n",
      " |-- daily_total_bid_amount: double (nullable = true)\n",
      " |-- daily_yes_volume: long (nullable = true)\n",
      " |-- daily_no_volume: long (nullable = true)\n",
      " |-- daily_total_volume: long (nullable = true)\n",
      " |-- 7_day_avg_invested_amount: double (nullable = true)\n",
      " |-- 7_day_avg_yes_invested_amount: double (nullable = true)\n",
      " |-- 7_day_avg_no_invested_amount: double (nullable = true)\n",
      " |-- daily_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_yes_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_no_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- 7_day_yes_momentum: long (nullable = true)\n",
      " |-- 7_day_no_momentum: long (nullable = true)\n",
      " |-- 3_day_avg_invested_amount: double (nullable = true)\n",
      " |-- 3_day_avg_yes_invested_amount: double (nullable = true)\n",
      " |-- 3_day_avg_no_invested_amount: double (nullable = true)\n",
      " |-- daily_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_yes_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_no_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- 3_day_yes_close_momentum: long (nullable = true)\n",
      " |-- 3_day_no_close_momentum: long (nullable = true)\n",
      " |-- daily_no_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_yes_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_total_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_no_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_yes_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_total_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- 3_day_yes_volume_momentum: long (nullable = true)\n",
      " |-- 3_day_no_volume_momentum: long (nullable = true)\n",
      " |-- market_title: string (nullable = true)\n",
      " |-- market_subtitle: string (nullable = true)\n",
      " |-- market_desc: string (nullable = true)\n",
      " |-- open_time: string (nullable = true)\n",
      " |-- close_time: string (nullable = true)\n",
      " |-- market_type: string (nullable = true)\n",
      " |-- event_title: string (nullable = true)\n",
      " |-- event_subtitle: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/26 18:28:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 18:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 24:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o386.parquet.\n: java.io.IOException: Failed to get result: java.io.IOException: Error accessing Bucket kalshi-data-lake with message : java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFromFuture(GoogleCloudStorageFileSystem.java:1047)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.repairImplicitDirectory(GoogleCloudStorageFileSystem.java:1017)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.delete(GoogleCloudStorageFileSystem.java:457)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$delete$7(GoogleHadoopFileSystemBase.java:918)\n\tat com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics.trackDuration(GhfsStorageStatistics.java:104)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.delete(GoogleHadoopFileSystemBase.java:906)\n\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:183)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:238)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:131)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:392)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:420)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:392)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:802)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.util.concurrent.ExecutionException: java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)\n\tat java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFromFuture(GoogleCloudStorageFileSystem.java:1040)\n\t... 52 more\nCaused by: java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getBucket(GoogleCloudStorageImpl.java:2280)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:2220)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfoInternal(GoogleCloudStorageFileSystem.java:1226)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.lambda$delete$2(GoogleCloudStorageFileSystem.java:391)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\nGET https://storage.googleapis.com/storage/v1/b/kalshi-data-lake\n{\n  \"code\" : 403,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"kalshi-data-loader@kalshi-456121.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\",\n    \"reason\" : \"forbidden\"\n  } ],\n  \"message\" : \"kalshi-data-loader@kalshi-456121.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\"\n}\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:439)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:525)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:466)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:576)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getBucket(GoogleCloudStorageImpl.java:2273)\n\t... 7 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 185\u001b[39m\n\u001b[32m    119\u001b[39m joined_df.printSchema()\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# joined_df = joined_df.select(\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m#     # Identifiers\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m#     \"ticker\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[38;5;66;03m#     \"3_day_no_volume_momentum\"\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[43mjoined_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepartition\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgs://kalshi-data-lake/processed_data/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# joined_df.write.mode(\"overwrite\").parquet(\"gs://kalshi-data-lake/processed_data/\")\u001b[39;00m\n\u001b[32m    188\u001b[39m joined_df.filter(col(\u001b[33m\"\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mKXFEDDECISION-25MAY-C25\u001b[39m\u001b[33m\"\u001b[39m).show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/apis/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1721\u001b[39m, in \u001b[36mDataFrameWriter.parquet\u001b[39m\u001b[34m(self, path, mode, partitionBy, compression)\u001b[39m\n\u001b[32m   1719\u001b[39m     \u001b[38;5;28mself\u001b[39m.partitionBy(partitionBy)\n\u001b[32m   1720\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(compression=compression)\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/apis/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/apis/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/apis/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o386.parquet.\n: java.io.IOException: Failed to get result: java.io.IOException: Error accessing Bucket kalshi-data-lake with message : java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFromFuture(GoogleCloudStorageFileSystem.java:1047)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.repairImplicitDirectory(GoogleCloudStorageFileSystem.java:1017)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.delete(GoogleCloudStorageFileSystem.java:457)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$delete$7(GoogleHadoopFileSystemBase.java:918)\n\tat com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics.trackDuration(GhfsStorageStatistics.java:104)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.delete(GoogleHadoopFileSystemBase.java:906)\n\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:183)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:238)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:131)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:392)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:420)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:392)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:802)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.util.concurrent.ExecutionException: java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)\n\tat java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFromFuture(GoogleCloudStorageFileSystem.java:1040)\n\t... 52 more\nCaused by: java.io.IOException: Error accessing Bucket kalshi-data-lake\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getBucket(GoogleCloudStorageImpl.java:2280)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:2220)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.getFileInfoInternal(GoogleCloudStorageFileSystem.java:1226)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.lambda$delete$2(GoogleCloudStorageFileSystem.java:391)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\nGET https://storage.googleapis.com/storage/v1/b/kalshi-data-lake\n{\n  \"code\" : 403,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"kalshi-data-loader@kalshi-456121.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\",\n    \"reason\" : \"forbidden\"\n  } ],\n  \"message\" : \"kalshi-data-loader@kalshi-456121.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\"\n}\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:439)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:525)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:466)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:576)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getBucket(GoogleCloudStorageImpl.java:2273)\n\t... 7 more\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID='kalshi-456121'\n",
    "BUCKET_NAME='kalshi-data-lake'\n",
    "CLUSTER='kalshi-dataproc-cluster'\n",
    "REGION='us-central1'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import last, min, max, when, col, lag, round, avg, expr, to_date, sum as spark_sum, monotonically_increasing_id\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from os.path import expanduser\n",
    "gcs_connector_path = expanduser(\"~/Documents/gcloud/gcs-connector-hadoop3-latest.jar\")\n",
    "\n",
    "# Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JoinAndAggregateKalshi\") \\\n",
    "    .config(\"spark.jars\", gcs_connector_path) \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"/Users/jakewatson/hello/kalshi/creds/gcp-sa-key.json\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", \"kalshi-456121\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "# ---------------- Trades ----------------- #    \n",
    "import os\n",
    "folder_path = f\"gs://{BUCKET_NAME}/trades/\"\n",
    "\n",
    "# Read them into one DataFrame\n",
    "trades_df = spark.read.parquet(f\"gs://{BUCKET_NAME}/trades/*.parquet\")\n",
    "trades_df = trades_df.withColumn(\n",
    "    \"bid_amount\", \n",
    "    round(\n",
    "        when(col(\"taker_side\") == \"yes\", col(\"yes_price\") * col(\"count\") / 100)\n",
    "        .when(col(\"taker_side\") == \"no\", (col(\"no_price\") * col(\"count\") / 100))\n",
    "        .otherwise(0), 2\n",
    "    )\n",
    ")\n",
    "trades_df = trades_df.withColumn(\"created_date\", to_date(\"created_time\"))\n",
    "trades_df.show(10)\n",
    "\n",
    "# # Define a window by market_ticker, ordered by trade creation time\n",
    "rolling_7_day_window = Window.partitionBy(\"ticker\").orderBy(\"created_date\").rowsBetween(-6, 0)\n",
    "rolling_3_day_window = Window.partitionBy(\"ticker\").orderBy(\"created_date\").rowsBetween(-2, 0)\n",
    "price_window = Window.partitionBy(\"ticker\", \"created_date\").orderBy(col(\"created_time\")).rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "momentum_window = Window.partitionBy(\"ticker\").orderBy(\"created_date\")\n",
    "\n",
    "# Apply last with enforced ordering using window\n",
    "trades_df = trades_df.withColumn(\"yes_price_close\", last(when(col(\"taker_side\") == \"yes\", col(\"yes_price\")), True).over(price_window)) \\\n",
    "                     .withColumn(\"no_price_close\", last(when(col(\"taker_side\") == \"no\", col(\"no_price\")), True).over(price_window)) \\\n",
    "                     .withColumn(\"yes_price_high\", max(when(col(\"taker_side\") == \"yes\", col(\"yes_price\"))).over(price_window)) \\\n",
    "                     .withColumn(\"no_price_high\", max(when(col(\"taker_side\") == \"no\", col(\"no_price\"))).over(price_window)) \\\n",
    "                     .withColumn(\"yes_price_low\", min(when(col(\"taker_side\") == \"yes\", col(\"yes_price\"))).over(price_window)) \\\n",
    "                     .withColumn(\"no_price_low\", min(when(col(\"taker_side\") == \"no\", col(\"no_price\"))).over(price_window))\n",
    "                     \n",
    "# ---------------- Trade Aggregations / Indicators ----------------- #                      \n",
    "aggs_df = trades_df.groupBy(\n",
    "    \"created_date\",\n",
    "    \"ticker\",\n",
    "    \"yes_price_close\",\n",
    "    \"yes_price_high\",\n",
    "    \"yes_price_low\",\n",
    "    \"no_price_close\", \n",
    "    \"no_price_high\",\n",
    "    \"no_price_low\"\n",
    ").agg(\n",
    "    spark_sum(when(col(\"taker_side\") == \"yes\", col(\"bid_amount\")).otherwise(0)).alias(\"daily_total_bid_amount_yes\"),\n",
    "    spark_sum(when(col(\"taker_side\") == \"no\", col(\"bid_amount\")).otherwise(0)).alias(\"daily_total_bid_amount_no\"),\n",
    "    spark_sum(\"bid_amount\").alias(\"daily_total_bid_amount\"),\n",
    "    spark_sum(when(col(\"taker_side\") == \"yes\", col(\"count\")).otherwise(0)).alias(\"daily_yes_volume\"),\n",
    "    spark_sum(when(col(\"taker_side\") == \"no\", col(\"count\")).otherwise(0)).alias(\"daily_no_volume\"),\n",
    "    spark_sum(\"count\").alias(\"daily_total_volume\")\n",
    ")\n",
    "\n",
    "aggs_df = aggs_df.withColumn(\"7_day_avg_invested_amount\", round(avg(\"daily_total_bid_amount\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"7_day_avg_yes_invested_amount\", round(avg(\"daily_total_bid_amount_yes\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"7_day_avg_no_invested_amount\", round(avg(\"daily_total_bid_amount_no\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"daily_total_vs_7_day_avg\", col(\"daily_total_bid_amount\") - round(avg(\"daily_total_bid_amount\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"daily_yes_total_vs_7_day_avg\", col(\"daily_total_bid_amount_yes\") - round(avg(\"daily_total_bid_amount_yes\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"daily_no_total_vs_7_day_avg\", col(\"daily_total_bid_amount_no\") - round(avg(\"daily_total_bid_amount_no\").over(rolling_7_day_window),2)) \\\n",
    "                .withColumn(\"7_day_yes_momentum\", col(\"yes_price_close\") - lag(\"yes_price_close\", 7).over(momentum_window)) \\\n",
    "                .withColumn(\"7_day_no_momentum\", col(\"no_price_close\") - lag(\"no_price_close\", 7).over(momentum_window)) \\\n",
    "                .withColumn(\"3_day_avg_invested_amount\", round(avg(\"daily_total_bid_amount\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"3_day_avg_yes_invested_amount\", round(avg(\"daily_total_bid_amount_yes\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"3_day_avg_no_invested_amount\", round(avg(\"daily_total_bid_amount_no\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"daily_total_vs_3_day_avg\", col(\"daily_total_bid_amount\") - round(avg(\"daily_total_bid_amount\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"daily_yes_total_vs_3_day_avg\", col(\"daily_total_bid_amount_yes\") - round(avg(\"daily_total_bid_amount_yes\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"daily_no_total_vs_3_day_avg\", col(\"daily_total_bid_amount_no\") - round(avg(\"daily_total_bid_amount_no\").over(rolling_3_day_window),2)) \\\n",
    "                .withColumn(\"3_day_yes_close_momentum\", col(\"yes_price_close\") - lag(\"yes_price_close\", 3).over(momentum_window)) \\\n",
    "                .withColumn(\"3_day_no_close_momentum\", col(\"no_price_close\") - lag(\"no_price_close\", 3).over(momentum_window)) \\\n",
    "                .withColumn(\"daily_no_volume_vs_7_day_avg\", col(\"daily_no_volume\") - avg(\"daily_no_volume\").over(rolling_7_day_window)) \\\n",
    "                .withColumn(\"daily_yes_volume_vs_7_day_avg\", col(\"daily_yes_volume\") - avg(\"daily_yes_volume\").over(rolling_7_day_window)) \\\n",
    "                .withColumn(\"daily_total_volume_vs_7_day_avg\", col(\"daily_total_volume\") - avg(\"daily_total_volume\").over(rolling_7_day_window)) \\\n",
    "                .withColumn(\"daily_no_volume_vs_3_day_avg\", col(\"daily_no_volume\") - avg(\"daily_no_volume\").over(rolling_3_day_window)) \\\n",
    "                .withColumn(\"daily_yes_volume_vs_3_day_avg\", col(\"daily_yes_volume\") - avg(\"daily_yes_volume\").over(rolling_3_day_window)) \\\n",
    "                .withColumn(\"daily_total_volume_vs_3_day_avg\", col(\"daily_total_volume\") - avg(\"daily_total_volume\").over(rolling_3_day_window)) \\\n",
    "                .withColumn(\"3_day_yes_volume_momentum\", col(\"daily_yes_volume\") - lag(\"daily_yes_volume\", 3).over(momentum_window)) \\\n",
    "                .withColumn(\"3_day_no_volume_momentum\", col(\"daily_no_volume\") - lag(\"daily_no_volume\", 3).over(momentum_window))\n",
    "                \n",
    "# aggs_df.filter(col(\"ticker\") == \"KXFEDDECISION-25MAY-C25\").show()\n",
    "\n",
    "# ---------------- Markets, Events ----------------- #                      \n",
    "markets_df = spark.read.parquet(f\"gs://{BUCKET_NAME}/markets/01012025_to_04242025.parquet\")\n",
    "markets_df = markets_df.select(\"ticker\", col(\"event_ticker\").alias(\"m_event_ticker\"), col(\"title\").alias(\"market_title\"), col(\"subtitle\").alias(\"market_subtitle\"), col(\"rules_primary\").alias(\"market_desc\"), \"open_time\", \"close_time\", \"market_type\")\n",
    "\n",
    "events_df = spark.read.parquet(f\"gs://{BUCKET_NAME}/events/all.parquet\")\n",
    "events_df = events_df.select(\"event_ticker\", \"series_ticker\", col(\"title\").alias(\"event_title\"), col(\"sub_title\").alias(\"event_subtitle\"), \"category\")\n",
    "\n",
    "# ---------------- Joined ----------------- #   \n",
    "joined_df = aggs_df.join(markets_df.alias(\"m\"), on=[\"ticker\"], how=\"inner\") \\\n",
    "                    .join(events_df.alias(\"e\"), on=col(\"m_event_ticker\") == col(\"e.event_ticker\"), how=\"inner\") \\\n",
    "                    .drop(\"m_event_ticker\", \"ticker\", \"event_ticker\", \"series_ticker\")\n",
    "\n",
    "joined_df.printSchema()\n",
    "\n",
    "# joined_df = joined_df.select(\n",
    "#     # Identifiers\n",
    "#     \"ticker\",\n",
    "#     \"event_ticker\",\n",
    "#     \"series_ticker\",\n",
    "#     \"created_date\",\n",
    "\n",
    "#     # Market/Event Info\n",
    "#     \"event_title\",\n",
    "#     \"market_title\",\n",
    "#     \"market_subtitle\",\n",
    "#     \"event_subtitle\",\n",
    "#     \"market_desc\",\n",
    "#     \"open_time\",\n",
    "#     \"close_time\",\n",
    "#     \"market_type\",\n",
    "#     \"category\",\n",
    "\n",
    "#     # Prices\n",
    "#     \"yes_price_high\",\n",
    "#     \"yes_price_low\",\n",
    "#     \"yes_price_close\",\n",
    "#     \"no_price_high\",\n",
    "#     \"no_price_low\",\n",
    "#     \"no_price_close\",\n",
    "\n",
    "#     # Daily Totals\n",
    "#     \"daily_yes_volume\",\n",
    "#     \"daily_no_volume\",\n",
    "#     \"daily_total_volume\",\n",
    "#     \"daily_total_bid_amount_yes\",\n",
    "#     \"daily_total_bid_amount_no\",\n",
    "#     \"daily_total_bid_amount\",\n",
    "\n",
    "#     # 7-Day Averages\n",
    "#     # volume averages\n",
    "#     \"7_day_avg_invested_amount\",\n",
    "#     \"7_day_avg_yes_invested_amount\",\n",
    "#     \"7_day_avg_no_invested_amount\",\n",
    "#     \"daily_total_vs_7_day_avg\",\n",
    "#     \"daily_yes_total_vs_7_day_avg\",\n",
    "#     \"daily_no_total_vs_7_day_avg\",\n",
    "#     \"7_day_yes_momentum\",\n",
    "#     \"7_day_no_momentum\",\n",
    "#     \"daily_no_volume_vs_7_day_avg\",\n",
    "#     \"daily_yes_volume_vs_7_day_avg\",\n",
    "#     \"daily_total_volume_vs_7_day_avg\",\n",
    "\n",
    "#     # 3-Day Averages\n",
    "#     \"3_day_avg_invested_amount\",\n",
    "#     \"3_day_avg_yes_invested_amount\",\n",
    "#     \"3_day_avg_no_invested_amount\",\n",
    "#     \"daily_total_vs_3_day_avg\",\n",
    "#     \"daily_yes_total_vs_3_day_avg\",\n",
    "#     \"daily_no_total_vs_3_day_avg\",\n",
    "#     \"3_day_yes_close_momentum\",\n",
    "#     \"3_day_no_close_momentum\",\n",
    "#     \"daily_no_volume_vs_3_day_avg\",\n",
    "#     \"daily_yes_volume_vs_3_day_avg\",\n",
    "#     \"daily_total_volume_vs_3_day_avg\",\n",
    "#     \"3_day_yes_volume_momentum\",\n",
    "#     \"3_day_no_volume_momentum\"\n",
    "# )\n",
    "\n",
    "joined_df.repartition(10).write.mode(\"overwrite\").parquet(\"gs://kalshi-data-lake/processed_data/\")\n",
    "# joined_df.write.mode(\"overwrite\").parquet(\"gs://kalshi-data-lake/processed_data/\")\n",
    "\n",
    "joined_df.filter(col(\"ticker\") == \"KXFEDDECISION-25MAY-C25\").show()\n",
    "joined_df.filter(col(\"market_title\").like(\"Who will the next Pope be?\")).show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6232db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -a gs://kalshi-data-lake/processed_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0024025",
   "metadata": {},
   "source": [
    "## Read Cleaned Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bea101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 223593\n",
      "root\n",
      " |-- created_date: date (nullable = true)\n",
      " |-- yes_price_close: long (nullable = true)\n",
      " |-- yes_price_high: long (nullable = true)\n",
      " |-- yes_price_low: long (nullable = true)\n",
      " |-- no_price_close: long (nullable = true)\n",
      " |-- no_price_high: long (nullable = true)\n",
      " |-- no_price_low: long (nullable = true)\n",
      " |-- daily_total_bid_amount_yes: double (nullable = true)\n",
      " |-- daily_total_bid_amount_no: double (nullable = true)\n",
      " |-- daily_total_bid_amount: double (nullable = true)\n",
      " |-- daily_yes_volume: long (nullable = true)\n",
      " |-- daily_no_volume: long (nullable = true)\n",
      " |-- daily_total_volume: long (nullable = true)\n",
      " |-- 7_day_avg_invested_amount: double (nullable = true)\n",
      " |-- 7_day_avg_yes_invested_amount: double (nullable = true)\n",
      " |-- 7_day_avg_no_invested_amount: double (nullable = true)\n",
      " |-- daily_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_yes_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_no_total_vs_7_day_avg: double (nullable = true)\n",
      " |-- 7_day_yes_momentum: long (nullable = true)\n",
      " |-- 7_day_no_momentum: long (nullable = true)\n",
      " |-- 3_day_avg_invested_amount: double (nullable = true)\n",
      " |-- 3_day_avg_yes_invested_amount: double (nullable = true)\n",
      " |-- 3_day_avg_no_invested_amount: double (nullable = true)\n",
      " |-- daily_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_yes_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_no_total_vs_3_day_avg: double (nullable = true)\n",
      " |-- 3_day_yes_close_momentum: long (nullable = true)\n",
      " |-- 3_day_no_close_momentum: long (nullable = true)\n",
      " |-- daily_no_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_yes_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_total_volume_vs_7_day_avg: double (nullable = true)\n",
      " |-- daily_no_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_yes_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- daily_total_volume_vs_3_day_avg: double (nullable = true)\n",
      " |-- 3_day_yes_volume_momentum: long (nullable = true)\n",
      " |-- 3_day_no_volume_momentum: long (nullable = true)\n",
      " |-- market_title: string (nullable = true)\n",
      " |-- market_subtitle: string (nullable = true)\n",
      " |-- market_desc: string (nullable = true)\n",
      " |-- open_time: string (nullable = true)\n",
      " |-- close_time: string (nullable = true)\n",
      " |-- market_type: string (nullable = true)\n",
      " |-- event_title: string (nullable = true)\n",
      " |-- event_subtitle: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+--------------+-------------+--------------+-------------+------------+--------------------------+-------------------------+----------------------+----------------+---------------+------------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------+-----------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------------+-----------------------+----------------------------+-----------------------------+-------------------------------+----------------------------+-----------------------------+-------------------------------+-------------------------+------------------------+--------------------+----------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------+--------+\n",
      "|created_date|yes_price_close|yes_price_high|yes_price_low|no_price_close|no_price_high|no_price_low|daily_total_bid_amount_yes|daily_total_bid_amount_no|daily_total_bid_amount|daily_yes_volume|daily_no_volume|daily_total_volume|7_day_avg_invested_amount|7_day_avg_yes_invested_amount|7_day_avg_no_invested_amount|daily_total_vs_7_day_avg|daily_yes_total_vs_7_day_avg|daily_no_total_vs_7_day_avg|7_day_yes_momentum|7_day_no_momentum|3_day_avg_invested_amount|3_day_avg_yes_invested_amount|3_day_avg_no_invested_amount|daily_total_vs_3_day_avg|daily_yes_total_vs_3_day_avg|daily_no_total_vs_3_day_avg|3_day_yes_close_momentum|3_day_no_close_momentum|daily_no_volume_vs_7_day_avg|daily_yes_volume_vs_7_day_avg|daily_total_volume_vs_7_day_avg|daily_no_volume_vs_3_day_avg|daily_yes_volume_vs_3_day_avg|daily_total_volume_vs_3_day_avg|3_day_yes_volume_momentum|3_day_no_volume_momentum|        market_title| market_subtitle|         market_desc|           open_time|          close_time|market_type|         event_title|event_subtitle|category|\n",
      "+------------+---------------+--------------+-------------+--------------+-------------+------------+--------------------------+-------------------------+----------------------+----------------+---------------+------------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------+-----------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------------+-----------------------+----------------------------+-----------------------------+-------------------------------+----------------------------+-----------------------------+-------------------------------+-------------------------+------------------------+--------------------+----------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------+--------+\n",
      "|  2025-04-24|             28|            31|           27|            74|           74|          70|         8442.570000000002|                  7255.36|    15697.930000000006|           28873|          10053|             38926|                 20253.42|                     13082.74|                     7170.68|     -4555.4899999999925|          -4640.169999999998|          84.67999999999938|              NULL|             NULL|                 23066.44|                     15496.07|                     7570.37|      -7368.509999999993|          -7053.499999999998|         -315.0100000000002|                      -7|                      9|                     -282.25|                     -13350.5|                      -13632.75|          -759.3333333333339|                     -21659.0|            -22418.333333333336|                    11575|                    1149|Who will the next...|        :: Italy|If Pietro Parolin...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-25|              1|             1|            1|          NULL|         NULL|        NULL|                      0.05|                      0.0|                  0.05|               5|              0|                 5|                   850.77|                        96.63|                      754.14|                 -850.72|                      -96.58|                    -754.14|              NULL|             NULL|                   170.99|                        78.92|                       92.07|                 -170.94|                      -78.87|                     -92.07|                      -1|                   NULL|                      -761.8|                      -8536.6|                        -9298.4|                       -93.0|                      -7670.0|                        -7763.0|                   -17998|                   -2004|Who will the next...|       :: Sweden|If Anders Arborel...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-22|              2|             2|            1|            99|           99|          99|                    274.77|                     0.99|                275.76|           26422|              1|             26423|                   250.94|                       151.44|                        99.5|      24.819999999999993|          123.32999999999998|                     -98.51|              NULL|             NULL|                   250.94|                       151.44|                        99.5|      24.819999999999993|          123.32999999999998|                     -98.51|                    NULL|                   NULL|                       -99.5|                      11829.0|                        11729.5|                       -99.5|                      11829.0|                        11729.5|                     NULL|                    NULL|Who will the next...|        :: Italy|If Angelo Scola b...|2025-04-21T21:10:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-24|              5|             8|            4|            96|           96|          93|        1647.1000000000001|        6906.460000000001|               8553.56|           28038|           7344|             35382|                 10203.36|                      2248.79|                     7954.57|      -1649.800000000001|          -601.6899999999998|        -1048.1099999999988|              NULL|             NULL|                 11727.99|                      2520.19|                      9207.8|     -3174.4300000000003|          -873.0899999999999|        -2301.3399999999983|                      -4|                      4|                     -1339.5|                      2466.75|                        1127.25|          -2678.333333333334|          -1592.3333333333321|             -4270.666666666664|                    14644|                    2677|Who will the next...|      :: Hungary|If Peter Erdo bec...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-24|              1|             2|            1|            99|           99|          99|         90.05000000000001|                  11385.0|    11475.050000000001|            8322|          11500|             19822|                  4927.91|                       171.95|                     4755.96|       6547.140000000001|          -81.89999999999998|                    6629.04|              NULL|             NULL|                  5916.09|                       195.87|                     5720.22|       5558.960000000001|                     -105.82|                    5664.78|                       0|                      0|                      6696.0|                     -5393.75|                        1302.25|                      5722.0|           -9060.333333333332|             -3338.333333333332|                     5606|                    9618|Who will the next...|:: United States|If Raymond Burke ...|2025-04-21T21:20:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-21|              1|             2|            1|            99|           99|          99|                     28.11|                    198.0|                226.11|            2764|            200|              2964|                   226.11|                        28.11|                       198.0|                     0.0|                         0.0|                        0.0|              NULL|             NULL|                   226.11|                        28.11|                       198.0|                     0.0|                         0.0|                        0.0|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|        :: Italy|If Angelo Scola b...|2025-04-21T21:10:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-21|              8|            15|            8|            93|           93|          90|                   1191.43|       2986.8899999999994|    4178.3200000000015|           10494|           3268|             13762|                  4178.32|                      1191.43|                     2986.89|    1.818989403545856...|                         0.0|       -4.54747350886464...|              NULL|             NULL|                  4178.32|                      1191.43|                     2986.89|    1.818989403545856...|                         0.0|       -4.54747350886464...|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|        :: Italy|If Pierbattista P...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-21|              2|             7|            2|            99|           99|          97|                     66.11|       1510.5400000000002|    1576.6500000000005|            1680|           1526|              3206|                  1576.65|                        66.11|                     1510.54|    4.547473508864641...|                         0.0|       2.273736754432320...|              NULL|             NULL|                  1576.65|                        66.11|                     1510.54|    4.547473508864641...|                         0.0|       2.273736754432320...|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|       :: Sweden|If Anders Arborel...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-23|              1|             2|            1|            99|           99|          99|                     74.49|                   2970.0|    3044.4900000000002|            6842|           3000|              9842|                  3044.49|                        74.49|                      2970.0|    4.547473508864641...|                         0.0|                        0.0|              NULL|             NULL|                  3044.49|                        74.49|                      2970.0|    4.547473508864641...|                         0.0|                        0.0|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|:: United States|If Robert Prevost...|2025-04-23T13:00:07Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-21|              9|            16|            7|            92|           92|          87|                    1434.6|        4194.870000000001|     5629.470000000004|           13394|           4667|             18061|                  5629.47|                       1434.6|                     4194.87|    3.637978807091713...|                         0.0|       9.094947017729282...|              NULL|             NULL|                  5629.47|                       1434.6|                     4194.87|    3.637978807091713...|                         0.0|       9.094947017729282...|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|      :: Hungary|If Peter Erdo bec...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-24|              2|             2|            2|            99|           99|          99|                    105.44|                  5559.84|     5665.279999999999|            5272|           5616|             10888|                  2994.07|                       365.98|                     2628.09|      2671.2099999999987|                     -260.54|                    2931.75|              NULL|             NULL|                  3806.76|                        322.1|                     3484.65|      1858.5199999999986|         -216.66000000000003|                    2075.19|                      -1|                      2|                      2948.5|                      -9076.0|                        -6127.5|          2079.3333333333335|           -9170.666666666666|             -7091.333333333332|                    -8792|                    5556|Who will the next...|       :: France|If Jean-Marc Avel...|2025-04-21T21:15:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-22|              2|             3|            2|            98|           98|          98|         577.8900000000002|                  4894.12|               5472.01|           23907|           4994|             28901|                  3014.01|                       537.75|                     2476.26|                  2458.0|          40.140000000000214|         2417.8599999999997|              NULL|             NULL|                  3014.01|                       537.75|                     2476.26|                  2458.0|          40.140000000000214|         2417.8599999999997|                    NULL|                   NULL|                      2467.0|                       4921.5|                         7388.5|                      2467.0|                       4921.5|                         7388.5|                     NULL|                    NULL|Who will the next...|       :: France|If Jean-Marc Avel...|2025-04-21T21:15:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-25|              2|             2|            2|          NULL|         NULL|        NULL|        1.8800000000000001|                      0.0|    1.8800000000000001|              94|              0|                94|                  6906.34|                        51.34|                      6855.0|                -6904.46|                      -49.46|                    -6855.0|              NULL|             NULL|                  6906.34|                        51.34|                      6855.0|                -6904.46|                      -49.46|                    -6855.0|                    NULL|                   NULL|                     -7000.0|                      -2573.0|                        -9573.0|                     -7000.0|                      -2573.0|                        -9573.0|                     NULL|                    NULL|Who will the next...|        :: Malta|If Mario Grech be...|2025-04-24T14:15:36Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-22|              2|             2|            1|            99|           99|          99|        180.26000000000005|                  1983.96|    2164.2200000000003|           18003|           2004|             20007|                  1870.44|                       123.19|                     1747.25|       293.7800000000002|           57.07000000000005|         236.71000000000004|              NULL|             NULL|                  1870.44|                       123.19|                     1747.25|       293.7800000000002|           57.07000000000005|         236.71000000000004|                    NULL|                   NULL|                       239.0|                       8161.5|                         8400.5|                       239.0|                       8161.5|                         8400.5|                     NULL|                    NULL|Who will the next...|       :: Sweden|If Anders Arborel...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-23|              1|             2|            1|            99|           99|          99|        177.51000000000002|       276.21000000000004|                453.72|           17100|            279|             17379|                   1398.2|                       141.29|                      1256.9|                 -944.48|           36.22000000000003|                    -980.69|              NULL|             NULL|                   1398.2|                       141.29|                      1256.9|                 -944.48|           36.22000000000003|                    -980.69|                    NULL|                   NULL|          -990.6666666666667|                       4839.0|              3848.333333333334|          -990.6666666666667|                       4839.0|              3848.333333333334|                     NULL|                    NULL|Who will the next...|       :: Sweden|If Anders Arborel...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-22|              1|             1|            1|          NULL|         NULL|        NULL|        16.509999999999998|                      0.0|    16.509999999999998|            1651|              0|              1651|                    16.51|                        16.51|                         0.0|    -3.55271367880050...|        -3.55271367880050...|                        0.0|              NULL|             NULL|                    16.51|                        16.51|                         0.0|    -3.55271367880050...|        -3.55271367880050...|                        0.0|                    NULL|                   NULL|                         0.0|                          0.0|                            0.0|                         0.0|                          0.0|                            0.0|                     NULL|                    NULL|Who will the next...|:: United States|If Joseph Tobin b...|2025-04-22T16:30:05Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-23|             30|            40|           27|            71|           74|          70|        19860.120000000006|       2025.8299999999997|              21885.95|           66472|           2837|             69309|                 21771.92|                     14629.47|                     7142.45|      114.03000000000247|           5230.650000000007|                   -5116.62|              NULL|             NULL|                 21771.92|                     14629.47|                     7142.45|      114.03000000000247|           5230.650000000007|                   -5116.62|                    NULL|                   NULL|          -7592.333333333334|           19798.333333333336|                        12206.0|          -7592.333333333334|           19798.333333333336|                        12206.0|                     NULL|                    NULL|Who will the next...|        :: Italy|If Pietro Parolin...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-25|             23|            24|           22|            78|           78|          77|         712.9300000000001|       2231.9800000000005|    2944.9100000000017|            3068|           2887|              5955|                 12962.65|                      6553.06|                     6409.59|     -10017.739999999998|                    -5840.13|                   -4177.61|              NULL|             NULL|                 11077.04|                      6408.33|                     4668.72|      -8132.129999999999|                     -5695.4|                   -2436.74|                      -2|                      2|                     -5384.0|                     -25169.8|            -30553.800000000003|                     -3146.0|          -25169.666666666668|            -28315.666666666664|                   -36495|                  -16627|Who will the next...|  :: Philippines|If Luis Antonio T...|2025-04-21T20:45:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-23|              2|             2|            1|            99|           99|          99|        384.46999999999997|                  8569.44|     8953.910000000002|           32863|           8656|             41519|                  3151.93|                       229.12|                     2922.81|       5801.980000000001|          155.34999999999997|          5646.630000000001|              NULL|             NULL|                  3151.93|                       229.12|                     2922.81|       5801.980000000001|          155.34999999999997|          5646.630000000001|                    NULL|                   NULL|           5703.666666666666|                      12180.0|             17883.666666666668|           5703.666666666666|                      12180.0|             17883.666666666668|                     NULL|                    NULL|Who will the next...|        :: Italy|If Angelo Scola b...|2025-04-21T21:10:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "|  2025-04-24|              8|             9|            8|            93|           93|          91|                    678.32|        5800.960000000001|     6479.280000000003|            8067|           6270|             14337|                  10133.4|                      2368.06|                     7765.34|     -3654.1199999999963|         -1689.7399999999998|        -1964.3799999999992|              NULL|             NULL|                 12250.61|                      2768.15|                     9482.46|      -5771.329999999997|                    -2089.83|         -3681.499999999998|                      -1|                      1|                    -2133.25|                     -18900.5|                      -21033.75|          -3992.666666666666|          -23006.666666666668|            -26999.333333333336|                    -6582|                    3445|Who will the next...|        :: Ghana|If Peter Turkson ...|2025-04-21T21:05:00Z|2035-01-01T15:00:00Z|     binary|Who will the next...|   Before 2035|   World|\n",
      "+------------+---------------+--------------+-------------+--------------+-------------+------------+--------------------------+-------------------------+----------------------+----------------+---------------+------------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------+-----------------+-------------------------+-----------------------------+----------------------------+------------------------+----------------------------+---------------------------+------------------------+-----------------------+----------------------------+-----------------------------+-------------------------------+----------------------------+-----------------------------+-------------------------------+-------------------------+------------------------+--------------------+----------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Confirmed JAR location\n",
    "jar_path = abspath(\"gcs-connector-hadoop3-latest.jar\")\n",
    "jars_url = f\"file://{jar_path}\"\n",
    "\n",
    "# GCS URI\n",
    "gcs_path = \"gs://kalshi-data-lake/processed_data\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"QueryGCSParquet\")\n",
    "        .master(\"local[*]\")\n",
    "\n",
    "        # Use the absolute file:// URL\n",
    "        .config(\"spark.jars\",                jars_url)\n",
    "        .config(\"spark.driver.extraClassPath\",   jars_url)\n",
    "        .config(\"spark.executor.extraClassPath\", jars_url)\n",
    "\n",
    "        # Make driver accessible on localhost\n",
    "        .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "        .config(\"spark.driver.host\",        \"127.0.0.1\")\n",
    "\n",
    "        # GCS connector implementations\n",
    "        .config(\"spark.hadoop.fs.gs.impl\",\n",
    "                \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "        .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\",\n",
    "                \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "        # Service-account auth\n",
    "        .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n",
    "        .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\",\n",
    "                \"creds/gcp-sa-key.json\")\n",
    "        .config(\"spark.hadoop.fs.gs.project.id\", \"kalshi-456121\")\n",
    "\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Now read your Parquet\n",
    "df = spark.read.parquet(f\"{gcs_path}/*.parquet\")\n",
    "print(\"Records:\", df.count())\n",
    "df.printSchema()\n",
    "df.filter(col(\"market_title\").like(\"Who will the next Pope be?\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e7d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
